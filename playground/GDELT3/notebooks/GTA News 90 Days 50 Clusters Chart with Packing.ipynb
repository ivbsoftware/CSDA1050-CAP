{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  GTA News 50 Clusters Chart Usiing Packed Circles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 50 cluster dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# directories\n",
    "dir_path = os.getcwd()\n",
    "#print('Working dir: ' + dir_path)\n",
    "\n",
    "local_path = dir_path + '\\\\..\\\\gta-news\\\\doc2vec\\data\\\\'\n",
    "df = pd.read_pickle(local_path+'backup'+'-gta.50'+'.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get cluster descriptions from titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../gta-news/doc2vec'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import d2v_utils\n",
    "skip_terms =['toronto','canada','canadian','ontario']\n",
    "cluster_descr = []\n",
    "clusters = df.groupby(['cluster'])['title']\n",
    "for cluster, titles in clusters:\n",
    "    #print(\"\\nCluster: \", cluster)\n",
    "    filtered_words = []\n",
    "    for title in titles:\n",
    "        t = title[0:-4]\n",
    "        #print(\">>>\", t)\n",
    "        tokens = d2v_utils.prepare_text_for_lda(t)\n",
    "        tokens = [word for word in tokens if word not in skip_terms and not word.isdigit()]\n",
    "        #print(\"  >\", tokens)\n",
    "        filtered_words = filtered_words + tokens\n",
    "    count = Counter(filtered_words)\n",
    "    current_clust_descr = count.most_common()[:10] \n",
    "    cluster_descr.append(current_clust_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cluster_descr[0][0:5])\n",
    "print(cluster_descr[1][0:5])\n",
    "print(cluster_descr[2][0:5])\n",
    "print(cluster_descr[3][0:5])\n",
    "print(cluster_descr[4][0:5])\n",
    "print(cluster_descr[5][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decriptions = []\n",
    "for row in cluster_descr:\n",
    "    d=[]\n",
    "    for token in row:\n",
    "        d.append(token[0])\n",
    "    decriptions.append(d)\n",
    "\n",
    "data = df\n",
    "description = []\n",
    "for i, row in df.iterrows():\n",
    "    description.append(decriptions[row['cluster']])\n",
    "\n",
    "data['description'] = description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need dfAggr:\n",
    "# date, cluster, count, description, x, y\n",
    "dfAggr = df[['date','cluster','description']].groupby(['date','cluster'])\\\n",
    "    .first().sort_values(['date','cluster']).reset_index()\n",
    "\n",
    "dfCount = df.groupby(['date','cluster'])['cluster']\\\n",
    "    .agg('count').to_frame('count')\\\n",
    "    .sort_values(['date','cluster']).reset_index()['count']\n",
    "\n",
    "dfAggr['count'] = dfCount\n",
    "\n",
    "# create topic string\n",
    "topics = []\n",
    "for i, row in dfAggr.iterrows():\n",
    "    topics.append(', '.join(row['description'][0:2]))\n",
    "dfAggr['topic'] = topics\n",
    "\n",
    "\n",
    "# temporary RANDOM\n",
    "import random\n",
    "import numpy as np\n",
    "random.seed(11)\n",
    "dfAggr['x'] = 0.0\n",
    "dfAggr['y'] = 0.0\n",
    "sampl_x = np.random.uniform(low=0.0, high=50.0, size=(50,))\n",
    "sampl_y = np.random.uniform(low=0.0, high=50.0, size=(50,))\n",
    "for i, row in dfAggr.iterrows():\n",
    "    dfAggr.at[i,'x'] = sampl_x[row.cluster]\n",
    "    dfAggr.at[i,'y'] = sampl_y[row.cluster]\n",
    "\n",
    "dfAggr.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfChart = dfAggr[['date','cluster','count','topic','x','y']].sort_values(['date','cluster'], ascending=[True,True])\n",
    "#dfChart = dfChart[dfChart['count'] > 2]\n",
    "\n",
    "#add 'day' column\n",
    "new_year_day = pd.Timestamp(year=2019, month=1, day=1)\n",
    "dfChart['day'] = 0\n",
    "for i, row in dfChart.iterrows():\n",
    "    dfChart.at[i,'day'] = (row['date'] - new_year_day).days + 1\n",
    "\n",
    "\n",
    "dfChart[dfChart.day == 110].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add missing rows (chart is not working well without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 50\n",
    "\n",
    "missing_rows = []\n",
    "cur_day = -1\n",
    "cl_num = 0\n",
    "len_total = len(dfChart.index)\n",
    "print(len_total)\n",
    "for i, row in dfChart.iterrows():\n",
    "\n",
    "    # day changed\n",
    "    if cur_day != row.day:\n",
    "        cur_day = row.day\n",
    "        cl_num = 0\n",
    "    \n",
    "    # create missing cluster row(s) before row.cluster\n",
    "    while cl_num != row.cluster:\n",
    "        desc = ', '.join(decriptions[cl_num][0:2])\n",
    "        d = pd.DataFrame(\n",
    "            {'date':[row.date],'cluster':[cl_num],'count':[0],'topic':[desc],\n",
    "             'x':[sampl_x[cl_num]],'y':[sampl_y[cl_num]],\n",
    "             'day':[row.day]}\n",
    "        )\n",
    "        missing_rows.append(d)\n",
    "        print (\"Created missing row: day:\" + str(row.day) + \", cluster:\" + str(cl_num) + \", topic:\" + desc)\n",
    "        cl_num += 1\n",
    "        if cl_num >= num_clusters:\n",
    "            break\n",
    "\n",
    "    # create missing cluster row(s) after row.cluster to end\n",
    "    if i < len_total:\n",
    "        if i == len_total -1:\n",
    "            next_day = -1\n",
    "        else:\n",
    "            next_day = dfChart.at[i+1,'day']\n",
    "        if next_day != cur_day:\n",
    "            cl_num += 1\n",
    "            while cl_num < num_clusters:\n",
    "                desc = ', '.join(decriptions[cl_num][0:2])\n",
    "                d = pd.DataFrame(\n",
    "                    {'date':[row.date],'cluster':[cl_num],'count':[0],'topic':[desc],\n",
    "                     'x':[sampl_x[cl_num]],'y':[sampl_y[cl_num]],\n",
    "                     'day':[row.day]}\n",
    "                )\n",
    "                missing_rows.append(d)\n",
    "                print (\"Created missing row: day:\" + str(row.day) + \", cluster:\" + str(cl_num) + \", topic:\" + desc)\n",
    "                cl_num += 1\n",
    "                if cl_num >= num_clusters:\n",
    "                    break\n",
    "            \n",
    "    cl_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfChart2 = dfChart.append(missing_rows, sort=True)\n",
    "dfChart2 = dfChart2.sort_values(['day','cluster'], ascending=[True,True])\n",
    "dfChart2 = dfChart2.reset_index(drop=True)\n",
    "dfChart2[dfChart2.day == 110].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Project clustering to 2D using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import PCA\n",
    "#pca = PCA(n_components=2)\n",
    "#principalComponents = pca.fit_transform(x)\n",
    "#principalDf = pd.DataFrame(data = principalComponents\n",
    "#             , columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px\n",
    "px.scatter(dfChart2, x=\"x\", y=\"y\", animation_frame=\"day\", animation_group=\"topic\",\n",
    "           size=\"count\", color=\"topic\", hover_name=\"topic\",\n",
    "           size_max=150, range_x=[-5,55], range_y=[-5,55])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
